{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "import sacrebleu\n",
    "import sentencepiece\n",
    "\n",
    "from fairseq import utils\n",
    "from fairseq.data import Dictionary, data_utils as fairseq_data_utils\n",
    "from fairseq.models.speech_to_text.xstnet import XSTNet\n",
    "from fairseq.data.audio.speech_text_triple_align_dataset import (\n",
    "    SpeechTextTripleAlignDataset\n",
    ")\n",
    "from fairseq.data.audio.speech_to_text_dataset import get_features_or_waveform, _collate_frames\n",
    "from ConST.prepare_data.data_utils import load_df_from_tsv, save_df_to_tsv\n",
    "from fairseq.checkpoint_utils import load_checkpoint_to_cpu, save_state, torch_persistent_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace()\n",
    "task = Namespace()\n",
    "\n",
    "args.w2v2_model_path = '/mnt/data/siqiouyang/runs/mST/pretrained/wav2vec_small.pt'\n",
    "\n",
    "args.max_audio_positions = 600000\n",
    "args.max_source_positions = 1024\n",
    "args.max_target_positions = 1024\n",
    "args.max_audio_tokens = 1000000\n",
    "args.max_text_tokens = 2000\n",
    "args.max_tokens = 1000000\n",
    "args.max_tokens_valid = 2000000\n",
    "\n",
    "tgt_dict = Dictionary.load('/mnt/data/siqiouyang/datasets/must-c-v1.0/spm_unigram10000_st_de.txt')\n",
    "task.target_dictionary = tgt_dict\n",
    "\n",
    "token_model = XSTNet.build_model(args, task)\n",
    "sent_model = XSTNet.build_model(args, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tag = 'ablation_data_efficiency_10h_token'\n",
    "sent_tag = 'ablation_data_efficiency_10h_token_triplet_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XSTNet(\n",
       "  (encoder): XSTNetEncoder(\n",
       "    (embed_tokens): Embedding(10000, 512, padding_idx=1)\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (wav2vec_model): Wav2Vec2Model(\n",
       "      (feature_extractor): ConvFeatureExtractionModel(\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "            (3): GELU()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout_input): Dropout(p=0.1, inplace=False)\n",
       "      (dropout_features): Dropout(p=0.1, inplace=False)\n",
       "      (quantizer): GumbelVectorQuantizer(\n",
       "        (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "      )\n",
       "      (project_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (encoder): TransformerEncoder(\n",
       "        (pos_conv): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "          (1): SamePad()\n",
       "          (2): GELU()\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (final_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       "    )\n",
       "    (subsample_audio): Conv1dSubsampler(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Conv1d(768, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "      )\n",
       "    )\n",
       "    (embed_positions): SinusoidalPositionalEmbedding()\n",
       "    (transformer_layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoderScriptable(\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (embed_tokens): Embedding(10000, 512, padding_idx=1)\n",
       "    (embed_positions): SinusoidalPositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (output_projection): Linear(in_features=512, out_features=10000, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ckpt_path = '/mnt/data/siqiouyang/runs/ConST/{}/checkpoint_best.pt'.format(token_tag)\n",
    "token_ckpt = load_checkpoint_to_cpu(token_ckpt_path)\n",
    "token_model.load_state_dict(token_ckpt['model'])\n",
    "token_model = token_model.to(device)\n",
    "token_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XSTNet(\n",
       "  (encoder): XSTNetEncoder(\n",
       "    (embed_tokens): Embedding(10000, 512, padding_idx=1)\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (wav2vec_model): Wav2Vec2Model(\n",
       "      (feature_extractor): ConvFeatureExtractionModel(\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "            (3): GELU()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "          (6): Sequential(\n",
       "            (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "            (2): GELU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout_input): Dropout(p=0.1, inplace=False)\n",
       "      (dropout_features): Dropout(p=0.1, inplace=False)\n",
       "      (quantizer): GumbelVectorQuantizer(\n",
       "        (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "      )\n",
       "      (project_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (encoder): TransformerEncoder(\n",
       "        (pos_conv): Sequential(\n",
       "          (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "          (1): SamePad()\n",
       "          (2): GELU()\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): TransformerSentenceEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (dropout_module): FairseqDropout()\n",
       "              (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (dropout1): Dropout(p=0.1, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (dropout3): Dropout(p=0.1, inplace=False)\n",
       "            (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (final_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       "    )\n",
       "    (subsample_audio): Conv1dSubsampler(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Conv1d(768, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (1): Conv1d(512, 1024, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "      )\n",
       "    )\n",
       "    (embed_positions): SinusoidalPositionalEmbedding()\n",
       "    (transformer_layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoderScriptable(\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (embed_tokens): Embedding(10000, 512, padding_idx=1)\n",
       "    (embed_positions): SinusoidalPositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerDecoderLayer(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (output_projection): Linear(in_features=512, out_features=10000, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_ckpt_path = '/mnt/data/siqiouyang/runs/ConST/{}/checkpoint_best.pt'.format(sent_tag)\n",
    "sent_ckpt = load_checkpoint_to_cpu(sent_ckpt_path)\n",
    "sent_model.load_state_dict(sent_ckpt['model'])\n",
    "sent_model = sent_model.to(device)\n",
    "sent_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm = sentencepiece.SentencePieceProcessor()\n",
    "spm.Load('/mnt/data/siqiouyang/datasets/must-c-v1.0/spm_unigram10000_st_de.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df_from_tsv('/mnt/data/siqiouyang/datasets/must-c-v1.0/tst-COMMON_st_de.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_inputs(df_idx):\n",
    "    audio_path = os.path.join('/mnt/data/siqiouyang/datasets/must-c-v1.0', df['audio'][df_idx])\n",
    "    audio = get_features_or_waveform(audio_path, need_waveform=True)\n",
    "    tokenized =  \" \".join(spm.EncodeAsPieces(df['src_text'][df_idx]))\n",
    "    src_text = tgt_dict.encode_line(\n",
    "        tokenized, add_if_not_exist=False, append_eos=True\n",
    "    ).long()\n",
    "    lang_tag = SpeechTextTripleAlignDataset.LANG_TAG_TEMPLATE.format(df['src_lang'][df_idx])\n",
    "    lang_tag_idx = tgt_dict.index(lang_tag)\n",
    "    src_text = th.cat((th.LongTensor([lang_tag_idx]), src_text), 0).unsqueeze(0)\n",
    "    n_frame = th.LongTensor([audio.size(1)])\n",
    "    src_length = th.LongTensor([src_text.size(1)])\n",
    "\n",
    "    # Target\n",
    "    tokenized = \" \".join(spm.EncodeAsPieces(df['tgt_text'][df_idx]))\n",
    "    tgt_text = tgt_dict.encode_line(\n",
    "        tokenized, add_if_not_exist=False, append_eos=True\n",
    "    ).long()\n",
    "    lang_tag = SpeechTextTripleAlignDataset.LANG_TAG_TEMPLATE.format(df['tgt_lang'][df_idx])\n",
    "    lang_tag_idx = tgt_dict.index(lang_tag)\n",
    "    tgt_text = th.cat((th.LongTensor([lang_tag_idx]), tgt_text), 0)\n",
    "\n",
    "    prev_output_target_tokens = fairseq_data_utils.collate_tokens(\n",
    "        [tgt_text],\n",
    "        tgt_dict.pad(),\n",
    "        tgt_dict.eos(),\n",
    "        left_pad=False,\n",
    "        move_eos_to_beginning=True,\n",
    "    )\n",
    "\n",
    "    return audio, n_frame, src_text, src_length, tgt_text, prev_output_target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_feature(model, df_idx):\n",
    "    audio, n_frame, src_text, src_length, tgt_text, prev_output_target_tokens = obtain_inputs(df_idx)\n",
    "\n",
    "    prev_output_target_tokens = fairseq_data_utils.collate_tokens(\n",
    "        [tgt_text],\n",
    "        tgt_dict.pad(),\n",
    "        tgt_dict.eos(),\n",
    "        left_pad=False,\n",
    "        move_eos_to_beginning=True,\n",
    "    )\n",
    "\n",
    "    with th.no_grad():\n",
    "        st_out = model(audio.to(device), n_frame.to(device), prev_output_target_tokens.to(device))\n",
    "        mt_out = model(src_text.to(device), src_length.to(device), prev_output_target_tokens.to(device), is_text_input=True)\n",
    "    \n",
    "    return st_out, mt_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6baa17c2131247629c820aaf1f11437b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2587 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_sims = []\n",
    "token_sims = []\n",
    "\n",
    "sent_dists = []\n",
    "token_dists = []\n",
    "\n",
    "for df_idx in tqdm(range(len(df))):\n",
    "    st_out, mt_out = compute_feature(sent_model, df_idx)\n",
    "    for l in range(1, 7):\n",
    "        sent_sims.extend(F.cosine_similarity(st_out[1]['inner_states'][l], mt_out[1]['inner_states'][l], dim=-1).flatten().cpu().tolist())\n",
    "        sent_dists.extend((st_out[1]['inner_states'][l] - mt_out[1]['inner_states'][l]).norm(dim=-1).flatten().cpu().tolist())\n",
    "    \n",
    "    st_out, mt_out = compute_feature(token_model, df_idx)\n",
    "    for l in range(1, 7):\n",
    "        token_sims.extend(F.cosine_similarity(st_out[1]['inner_states'][l], mt_out[1]['inner_states'][l], dim=-1).flatten().cpu().tolist())\n",
    "        token_dists.extend((st_out[1]['inner_states'][l] - mt_out[1]['inner_states'][l]).norm(dim=-1).flatten().cpu().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fa5f5444fd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 423.75x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = pd.DataFrame(columns=['sim', 'tag'])\n",
    "plot_df['sim'] = sent_sims + token_sims\n",
    "plot_df['tag'] = ['sent'] * len(sent_sims) + ['token'] * len(token_sims)\n",
    "sns.displot(plot_df, x='sim', hue='tag', bins=30, binrange=(0.6, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fa5f544b640>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 423.75x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = pd.DataFrame(columns=['distance', 'tag'])\n",
    "plot_df['distance'] = sent_dists + token_dists\n",
    "plot_df['tag'] = ['sent'] * len(sent_sims) + ['token'] * len(token_sims)\n",
    "sns.displot(plot_df, x='distance', hue='tag', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path):\n",
    "    refs = []\n",
    "    gens = []\n",
    "    with open(path, 'r') as r:\n",
    "        for line in r.readlines():\n",
    "            line = line.strip()\n",
    "            parts = line.split('\\t')\n",
    "            if line.startswith('T-'):\n",
    "                idx = int(parts[0][2:])\n",
    "                refs.append((idx, parts[1]))\n",
    "            elif line.startswith('D-'):\n",
    "                idx = int(parts[0][2:])\n",
    "                gens.append((idx, parts[2]))\n",
    "    \n",
    "    _, refs = list(zip(*sorted(refs)))\n",
    "    _, gens = list(zip(*sorted(gens)))\n",
    "\n",
    "    return refs, gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_root = '/home/siqiouyang/work/projects/ConST/ConST/analysis/generation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs, token_gens = extract(os.path.join(gen_root, token_tag, 'generate-tst-COMMON_st_de.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = np.array(refs)\n",
    "token_gens = np.array(token_gens)\n",
    "# sent_gens = np.array(sent_gens)\n",
    "token_bleu = []\n",
    "for ref, gen in zip(refs, token_gens):\n",
    "    token_bleu.append(sacrebleu.sentence_bleu(gen, [ref]).score)\n",
    "# sent_bleu = []\n",
    "# for ref, gen in zip(refs, sent_gens):\n",
    "    # sent_bleu.append(sacrebleu.sentence_bleu(gen, [ref]).score)\n",
    "token_bleu = np.array(token_bleu)\n",
    "# sent_bleu = np.array(sent_bleu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance level check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237c68eeb1c94249bf59cc08853f9381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2587 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_lengths = []\n",
    "for idx in tqdm(range(len(df))):\n",
    "    inputs = obtain_inputs(idx)\n",
    "    target_lengths.append(inputs[4].size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427308, 427308)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(target_lengths) * 6, len(token_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_len = 0\n",
    "token_sims_per_instance = []\n",
    "for idx in range(len(df)):\n",
    "    token_sims_per_instance.append(sum(token_sims[sum_len * 6 + target_lengths[idx] * 5 : (sum_len + target_lengths[idx]) * 6]) / target_lengths[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.040247031315044035, 0.04066721327137911)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.pearsonr(token_sims_per_instance, token_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ConST')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b19e2bae1ea557e2a235ed68e1ca6fc95eb26397d1b9313344955976d03228b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
