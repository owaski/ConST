{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from ConST.prepare_data.data_utils import load_df_from_tsv, save_df_to_tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/home/siqiouyang/work/projects/ConST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base\n",
    "prefix = '/mnt/data2/siqiouyang/runs/ConST'\n",
    "names = ['ablation_data_efficiency_1h_baseline', 'ablation_data_efficiency_10h_baseline']\n",
    "tags = ['base_ft_1h', 'base_ft_10h']\n",
    "for name, tag in zip(tqdm(names), tags):\n",
    "    cmd = \"\"\"CUDA_VISIBLE_DEVICES=0 python fairseq_cli/generate.py /mnt/data/siqiouyang/datasets/must-c-v1.0/ --gen-subset tst-COMMON_st_de --task speech_to_text \\\n",
    "    --prefix-size 1 --max-tokens 4000000 --max-source-positions 4000000 --beam 10 --lenpen 0.6 --scoring sacrebleu \\\n",
    "    --config-yaml config_st_de.yaml  --path {}/{}/checkpoint_best.pt \\\n",
    "    --results-path /home/siqiouyang/work/projects/ConST/ConST/analysis/generation/{}\"\"\".format(prefix, name, tag)\n",
    "    pipe = subprocess.Popen('cd {}; {}'.format(work_dir, cmd), stdin=subprocess.DEVNULL, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, shell=True)\n",
    "    res = pipe.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ctc_pt_1348h_ft_1h\n",
      "Running ctc_pt_1348h_ft_10h\n",
      "Running sent_pt_1348h_ft_1h\n",
      "Running sent_pt_1348h_ft_10h\n"
     ]
    }
   ],
   "source": [
    "# CTC and Sent\n",
    "prefix = '/mnt/data2/siqiouyang/runs/ConST'\n",
    "name_temp = 'ablation_pretrain_{}{}_ft_{}h'\n",
    "for method in ['ctc', 'sent']:\n",
    "    for pt_h in [1348]: # [10, 100, 370, 1348]:\n",
    "        for ft_h in [1, 10]:\n",
    "            if ft_h < pt_h:\n",
    "                name = name_temp.format(method, '_{}h'.format(pt_h) if pt_h != 370 else '', ft_h)\n",
    "                tag = '{}_pt_{}h_ft_{}h'.format(method, pt_h, ft_h)\n",
    "                cmd = \"\"\"CUDA_VISIBLE_DEVICES=0 python fairseq_cli/generate.py /mnt/data/siqiouyang/datasets/must-c-v1.0/ --gen-subset tst-COMMON_st_de --task speech_to_text \\\n",
    "                --prefix-size 1 --max-tokens 4000000 --max-source-positions 4000000 --beam 10 --lenpen 0.6 --scoring sacrebleu \\\n",
    "                --config-yaml config_st_de.yaml  --path {}/{}/checkpoint_best.pt \\\n",
    "                --results-path /home/siqiouyang/work/projects/ConST/ConST/analysis/generation/{}\"\"\".format(prefix, name, tag)\n",
    "                print('Running', tag)\n",
    "                pipe = subprocess.Popen('cd {}; {}'.format(work_dir, cmd), stdin=subprocess.DEVNULL, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, shell=True)\n",
    "                res = pipe.communicate()\n",
    "                # print(res)\n",
    "                # break             \n",
    "            # break\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running token_pt_1348h_ft_1h\n",
      "Running token_pt_1348h_ft_10h\n"
     ]
    }
   ],
   "source": [
    "# WACO\n",
    "prefix = '/mnt/data/siqiouyang/runs/ConST'\n",
    "name_temp = 'ablation_pretrain_token_mfat{}_t0.20_ft_{}h'\n",
    "for pt_h in [1348]: # [10, 100, 370, 1348]:\n",
    "    for ft_h in [1, 10]:\n",
    "        if ft_h < pt_h:\n",
    "            name = name_temp.format('_{}h'.format(pt_h) if pt_h != 370 else '', ft_h)\n",
    "            tag = 'token_pt_{}h_ft_{}h'.format(pt_h, ft_h)\n",
    "            cmd = \"\"\"CUDA_VISIBLE_DEVICES=0 python fairseq_cli/generate.py /mnt/data/siqiouyang/datasets/must-c-v1.0/ --gen-subset tst-COMMON_st_de --task speech_to_text \\\n",
    "            --prefix-size 1 --max-tokens 4000000 --max-source-positions 4000000 --beam 10 --lenpen 0.6 --scoring sacrebleu \\\n",
    "            --config-yaml config_st_de.yaml  --path {}/{}/checkpoint_best.pt \\\n",
    "            --results-path /home/siqiouyang/work/projects/ConST/ConST/analysis/generation/{}\"\"\".format(prefix, name, tag)\n",
    "            print('Running', tag)\n",
    "            pipe = subprocess.Popen('cd {}; {}'.format(work_dir, cmd), stdin=subprocess.DEVNULL, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, shell=True)\n",
    "            res = pipe.communicate()\n",
    "            # print(res)\n",
    "            # break\n",
    "        # break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.scoring.tokenizer import EvaluationTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = EvaluationTokenizer(\n",
    "    tokenizer_type='13a',\n",
    "    lowercase=False,\n",
    "    character_tokenization=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path):\n",
    "    refs = []\n",
    "    gens = []\n",
    "    with open(path, 'r') as r:\n",
    "        for line in r.readlines():\n",
    "            line = line.strip('\\n')\n",
    "            parts = line.split('\\t')\n",
    "            if line.startswith('T-'):\n",
    "                refs.append(tokenizer.tokenize(parts[1]))\n",
    "            elif line.startswith('D-'):\n",
    "                gens.append(tokenizer.tokenize(parts[2]))\n",
    "    return refs, gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_root = '/home/siqiouyang/work/projects/ConST/ConST/analysis/generation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = {}\n",
    "for pt_h in [10, 100, 370, 1348]:\n",
    "    for ft_h in [1, 10]:\n",
    "        if ft_h < pt_h:\n",
    "            ref, base = extract(os.path.join(gen_root, 'base_ft_{}h'.format(ft_h), 'generate-tst-COMMON_st_de.txt'))\n",
    "            ref, ctc = extract(os.path.join(gen_root, 'ctc_pt_{}h_ft_{}h'.format(pt_h, ft_h), 'generate-tst-COMMON_st_de.txt'))\n",
    "            ref, sent = extract(os.path.join(gen_root, 'sent_pt_{}h_ft_{}h'.format(pt_h, ft_h), 'generate-tst-COMMON_st_de.txt'))\n",
    "            ref, token = extract(os.path.join(gen_root, 'token_pt_{}h_ft_{}h'.format(pt_h, ft_h), 'generate-tst-COMMON_st_de.txt'))\n",
    "            translation[(pt_h, ft_h)] = [np.array(base), np.array(ctc), np.array(sent), np.array(token), np.array(ref)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_resample = 1000\n",
    "subset_ratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(ref, gen):\n",
    "    return sacrebleu.corpus_bleu(\n",
    "        gen, [ref], tokenize=\"none\"\n",
    "    ).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt 10h ft 1h: 100%|██████████| 1000/1000 [04:06<00:00,  4.05it/s]\n",
      "pt 100h ft 1h: 100%|██████████| 1000/1000 [04:39<00:00,  3.58it/s]\n",
      "pt 100h ft 10h: 100%|██████████| 1000/1000 [04:40<00:00,  3.57it/s]\n",
      "pt 370h ft 1h: 100%|██████████| 1000/1000 [04:57<00:00,  3.36it/s]\n",
      "pt 370h ft 10h: 100%|██████████| 1000/1000 [04:50<00:00,  3.44it/s]\n",
      "pt 1348h ft 1h: 100%|██████████| 1000/1000 [04:46<00:00,  3.49it/s]\n",
      "pt 1348h ft 10h: 100%|██████████| 1000/1000 [04:41<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "var_ctc = {}\n",
    "var_sent = {}\n",
    "var_token = {}\n",
    "for pt_h, ft_h in translation:\n",
    "    base, ctc, sent, token, ref = translation[(pt_h, ft_h)]\n",
    "\n",
    "    n_sample = len(ref)\n",
    "    indices = list(range(n_sample))\n",
    "    subset_size = int(n_sample * subset_ratio)\n",
    "\n",
    "    b_ctcs = []\n",
    "    b_sents = []\n",
    "    b_tokens = []\n",
    "    \n",
    "    for _ in tqdm(range(n_resample), desc='pt {}h ft {}h'.format(pt_h, ft_h)):\n",
    "        subset_indices = np.random.choice(indices, subset_size, replace=True)\n",
    "        \n",
    "        s_base = base[subset_indices]\n",
    "        s_ctc = ctc[subset_indices]\n",
    "        s_sent = sent[subset_indices]\n",
    "        s_token = token[subset_indices]\n",
    "        s_ref = ref[subset_indices]\n",
    "\n",
    "        # b_base = compute_bleu(s_ref, s_base)\n",
    "        b_ctc = compute_bleu(s_ref, s_ctc)\n",
    "        b_sent = compute_bleu(s_ref, s_sent)\n",
    "        b_token = compute_bleu(s_ref, s_token)\n",
    "\n",
    "        b_ctcs.append(b_ctc)\n",
    "        b_sents.append(b_sent)\n",
    "        b_tokens.append(b_token)\n",
    "\n",
    "    var_ctc[(pt_h, ft_h)] = np.std(b_ctcs)\n",
    "    var_sent[(pt_h, ft_h)] = np.std(b_sents)\n",
    "    var_token[(pt_h, ft_h)] = np.std(b_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(10, 1): 0.06868473959952008,\n",
       " (100, 1): 0.6377625731120373,\n",
       " (100, 10): 0.7929620046123323,\n",
       " (370, 1): 0.6824153498927058,\n",
       " (370, 10): 0.7864747298705266,\n",
       " (1348, 1): 0.6865655595291114,\n",
       " (1348, 10): 0.7765692260585267}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_ctc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(10, 1): 0.3091822828372738,\n",
       " (100, 1): 0.4558751497996544,\n",
       " (100, 10): 0.7114891039330945,\n",
       " (370, 1): 0.6013871011759279,\n",
       " (370, 10): 0.7227868288842159,\n",
       " (1348, 1): 0.7222100609970917,\n",
       " (1348, 10): 0.7462541912677322}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(10, 1): 0.7479468247559244,\n",
       " (100, 1): 0.7826973369312127,\n",
       " (100, 10): 0.7891808722509748,\n",
       " (370, 1): 0.9486531381462882,\n",
       " (370, 10): 0.834735564908792,\n",
       " (1348, 1): 0.8216657202401139,\n",
       " (1348, 10): 0.8248390147723607}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ConST",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
